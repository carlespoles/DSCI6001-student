{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 6001 5.1.Lab\n",
    "\n",
    "## QR Factorization\n",
    "\n",
    "So far you have already learned the $LU$ decomposition/factorization, which was by far the most common method of obtaining a solution to a linear system for some time, until the *Francis method* of $QR$ decomposition came about in the 60's. The Francis method $QR$ decomposition not only gives the eigenvectors to a matrix, but the eigenvalues and the solution to the system as well. $LU$ is still the most common method for decomposing small matrices as it's somewhat faster, but less stable. \n",
    "\n",
    "Shortly after this, methods involving *Givens rotations* and *Householder reflections* came about (better stability). The latter method is the best for larger matrices. For very large matrices only approximate methods are possible even today due to the high order ( $O(N^{3})$ ) of all of these algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts\n",
    "\n",
    "It is a **theorem** that *any nonsingular (invertible) matrix can be factored into a product of two matrices*: A matrix $Q$ of orthogonal vectors (representing an image-preserving map), and an upper-right triangular matrix $R$ much like the $U$ matrix of the $LU$ factorization. From this we may obtain a unique solution to the system.\n",
    "\n",
    "#### Factoring noninvertible matrices (?!?!) \n",
    "\n",
    "So far all your effort (and for the rest of this class) has been bent on factoring invertible or nonsingular matrices. It may seem perhaps that there are at least as many examples of noninvertible or singular matrices that might need to be factored. \n",
    "\n",
    "In this case, matrix factorization proceeds by a **least-squares** algorithm. This will be covered somewhat later. Least-squares methods are what are used in industry to provide matrix factorizations at scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the QR factorization\n",
    "\n",
    "Let us describe a square **matrix, A**:\n",
    "\n",
    "$$ {\\bf{A}} = \\{\\vec{a_{,1}}, \\vec{a_{,2}}, \\vec{a_{,3}}, \\cdots, \\vec{a_{,n}}\\}$$\n",
    "\n",
    "Now let us apply the Gram-Schmidt process to the columns of ${\\bf{A}}$, to obtain a new set of orthonormal column vectors. These vectors describe an orthornormal projection of the image space of the original ${\\bf{A}}$:\n",
    "\n",
    "$$q_1 = \\dfrac{u_{,1}}{\\|u_{,1}\\|}; u_{,1} = a_{,1}$$\n",
    "\n",
    "$$q_2 =  \\dfrac{u_{,2}}{\\|u_{,2}\\|}; u_{,2} = a_{,2}-(a_{,2} \\cdot u_{,1}) u_{,1}$$\n",
    "\n",
    "$$q_3 = \\dfrac{u_{,3}}{\\|u_{,3}\\|}; u_{,3} = a_{,3}-(a_{,3} \\cdot u_{,2}) u_{,2} -(a_{,3} \\cdot u_{,1}) u_{,1}$$\n",
    "\n",
    "$$\\vdots$$\n",
    "\n",
    "$$q_{k+1} = \\dfrac{u_{,k+1}}{\\|u_{,k+1}\\|}; u_{,k+1} = a_{,k+1} - \\sum_{n=1}^{k}(a_{,k+1} \\cdot u_{,n})u_{,n}$$\n",
    "\n",
    "And hence form the $N$ columns of the matrix ${\\bf{Q}}$:\n",
    "\n",
    "$${\\bf{Q}} = \\begin{bmatrix} \\vec{q_1} & \\vec{q_2} & \\cdots & \\vec{q_{N}}\\end{bmatrix}$$\n",
    "\n",
    "Now it so turns out that this happens to be a decomposition of ${\\bf{A}}$ if we realize that we can dot the rows of ${\\bf{Q}}$ with another matrix if we want to simply return the elements of ${\\bf{A}}$:\n",
    "\n",
    "$$\\begin{bmatrix} a_{1,1} & a_{1,2} & \\cdots & a_{1,N}\\\\ a_{2,1} & a_{2,2} & \\cdots & a_{2,N}\\\\ \\cdots & \\cdots & \\cdots & \\cdots \\\\ a_{N,1} & a_{M,2} & \\cdots & a_{N,N}\n",
    "\\end{bmatrix} = \\begin{bmatrix} q_{1,1} & q_{1,2} & \\cdots & q_{1,N}\\\\ q_{2,1} & q_{2,2} & \\cdots & q_{2,N}\\\\ \\cdots & \\cdots & \\cdots & \\cdots \\\\ q_{M,1} & q_{M,2} & \\cdots & q_{M,N}\n",
    "\\end{bmatrix}\\begin{bmatrix} q_{1,1}a_{1,1} & q_{1,2}a_{1,2} & \\cdots & q_{1,N}a_{1,N}\\\\ 0 & q_{2,2}a_{2,2} & \\cdots & q_{2,N}a_{2,N}\\\\ 0 & 0 & \\cdots & \\cdots \\\\ 0 & 0 & 0 & q_{N,N}a_{N,N}\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$${\\bf{Q}} = \\begin{bmatrix} | & | & |\\\\\n",
    "                             q_{,1} & q_{,2} & q_{,3} \\\\  \n",
    "                             | & | & | \\end{bmatrix}$$\n",
    "\n",
    "$${\\bf{R}} = \\begin{bmatrix} a_{,1} \\cdot q_{,1} & a_{,2} \\cdot q_{,1} & a_{,3} \\cdot q_{,1} \\\\\n",
    "                             0 & a_{,2} \\cdot q_{,2} & a_{,3} \\cdot q_{,2}  \\\\  \n",
    "                             0 & 0 & a_{,3} \\cdot q_{,3} \\end{bmatrix}$$\n",
    "\n",
    "This is because each element of ${\\bf{Q}}$ contains the magnitude of the dot product, thus the inner product of each row by column results in the appropriate element of ${\\bf{A}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "Compute the QR factorization for the matrix using Gramm-Schmidt:\n",
    "\n",
    "$$\\begin{bmatrix} 1 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "$$ \\vec{u^{(1)}} = \\vec{a^{(1)}}$$\n",
    "$$\\vec{q_{,1}} =\\dfrac{u_{,1}}{\\|u_{,1}\\|} = \\dfrac{1}{\\sqrt{2}}\\begin{bmatrix}1\\\\1\\\\0\\end{bmatrix}$$\n",
    "\n",
    "$$ \\vec{u_{,2}} = a_{,2}-(a_{,2} \\cdot u_{,1}) u_{,1} = \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} - \\dfrac{1}{\\sqrt{2}}\\begin{bmatrix}\\dfrac{1}{\\sqrt{2}}\\\\\\dfrac{1}{\\sqrt{2}}\\\\0\\end{bmatrix} =  \\begin{bmatrix}\\dfrac{1}{2}\\\\-\\dfrac{1}{2}\\\\1\\end{bmatrix}$$\n",
    "\n",
    "$$\\vec{q_{,2}} = \\dfrac{u_{,2}}{\\|u_{,2}\\|} = \\begin{bmatrix}\\dfrac{1}{\\sqrt{6}}\\\\-\\dfrac{1}{\\sqrt{6}}\\\\ \\dfrac{2}{\\sqrt{6}}\\end{bmatrix}$$\n",
    "\n",
    "$$ \\vec{u_{,3}} = a_{,3}-(a_{,3} \\cdot u_{,2}) u_{,2}-(a_{,3} \\cdot u_{,1}) u_{,1} $$\n",
    "\n",
    "$$ \\vec{u_{,3}} = \\begin{bmatrix}0\\\\1\\\\1\\end{bmatrix} -\\dfrac{1}{\\sqrt{6}}\\begin{bmatrix}\\dfrac{1}{\\sqrt{6}}\\\\-\\dfrac{1}{\\sqrt{6}}\\\\ \\dfrac{2}{\\sqrt{6}}\\end{bmatrix} - \\dfrac{1}{\\sqrt{2}}\\begin{bmatrix}\\dfrac{1}{\\sqrt{2}}\\\\\\dfrac{1}{\\sqrt{2}}\\\\0\\end{bmatrix} = \\begin{bmatrix}-\\dfrac{1}{\\sqrt{3}}\\\\\\dfrac{1}{\\sqrt{3}}\\\\ \\dfrac{1}{\\sqrt{3}}\\end{bmatrix}$$\n",
    "\n",
    "Thus we have a full basis for the image space of $\\bf{Q}$:\n",
    "\n",
    "$$\\left\\{ \\begin{bmatrix}\\dfrac{1}{\\sqrt{2}} \\\\ \\dfrac{1}{\\sqrt{2}}\\\\0 \\end{bmatrix}, \\begin{bmatrix}\\dfrac{1}{\\sqrt{6}}\\\\-\\dfrac{1}{\\sqrt{6}}\\\\ \\dfrac{2}{\\sqrt{6}}\\end{bmatrix}, \\begin{bmatrix}-\\dfrac{1}{\\sqrt{3}}\\\\\\dfrac{1}{\\sqrt{3}}\\\\ \\dfrac{1}{\\sqrt{3}}\\end{bmatrix}  \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can construct Q confidently:\n",
    "\n",
    "$${\\bf{Q}} = \\begin{bmatrix}\\dfrac{1}{\\sqrt{2}} & \\dfrac{1}{\\sqrt{6}} & -\\dfrac{1}{\\sqrt{3}} \\\\ \\dfrac{1}{\\sqrt{2}} & -\\dfrac{1}{\\sqrt{6}} & \\dfrac{1}{\\sqrt{3}} \\\\ 0 & \\dfrac{2}{\\sqrt{6}} & \\dfrac{1}{\\sqrt{3}} \\end{bmatrix}$$\n",
    "\n",
    "And R follows simply with elements that are the proscribed dot products:\n",
    "\n",
    "$${\\bf{R}} = \\begin{bmatrix}\\dfrac{\\sqrt{2}}{2} & \\dfrac{1}{\\sqrt{3}} & \\dfrac{1}{\\sqrt{2}} \\\\ 0 & \\dfrac{3}{\\sqrt{6}} & \\dfrac{1}{\\sqrt{6}} \\\\ 0 & 0 & \\dfrac{2}{\\sqrt{3}} \\end{bmatrix}$$\n",
    "\n",
    "### QUIZ:\n",
    "\n",
    "Satisfy yourself that this is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 0 1]\n",
      " [0 1 1]]\n",
      "[[  4.08248290e-01   7.07106781e-01   5.77350269e-01]\n",
      " [ -8.16496581e-01   1.19612948e-17   5.77350269e-01]\n",
      " [  4.08248290e-01  -7.07106781e-01   5.77350269e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from math import copysign, hypot\n",
    "\n",
    "A = np.array([[1, 1, 0 ],[1, 0, 1],[0, 1, 1]])\n",
    "\n",
    "print(A)\n",
    "\n",
    "(l, Q) = LA.eig(A)\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: \n",
    "\n",
    "Use the Gramm-Schmidt algorithm (by hand) to produce the QR factorization of the following matrix:\n",
    "\n",
    "$$ A = \\begin{bmatrix} -2 & 0 & 1\\\\ 1 & -2 & 1 \\\\ 1 & -1 & 0\\end{bmatrix}$$\n",
    "\n",
    "Show most of your steps. You may use the computer to check your steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:\n",
    "\n",
    "Write the Gramm-Schmidt algorithm using the code stub below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gs(X, row_vecs=False, norm = True): # here we have options for discussing row vectors (should be false) and norming\n",
    "                                        # should be true almost all of the time\n",
    "    if not row_vecs: \n",
    "        X = X.T\n",
    "    \n",
    "    Y = X[0:1,:].copy()\n",
    "    for i in range(1, X.shape[0]):\n",
    "        proj = np.diag((X[i,:].dot(Y.T)/np.linalg.norm(Y,axis=1)**2).flat).dot(Y)\n",
    "        Y = np.vstack((Y, X[i,:] - proj.sum(0)))\n",
    "        \n",
    "    if norm:\n",
    "        Y = np.diag(1/np.linalg.norm(Y,axis=1)).dot(Y)\n",
    "    if row_vecs:\n",
    "        return Y\n",
    "    else:\n",
    "        return Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gs(X, row_vecs=False, norm = True): # here we have options for discussing row vectors (should be false) and norming\n",
    "                                        # should be true almost all of the time\n",
    "    if not row_vecs:\n",
    "        X = X.T\n",
    "    Y = X[0:1,:].copy()\n",
    "    for i in range(1, X.shape[0]):\n",
    "        proj = np.diag((X[i,:].dot(Y.T)/np.linalg.norm(Y,axis=1)**2).flat).dot(Y)\n",
    "        Y = np.vstack((Y, X[i,:] - proj.sum(0)))\n",
    "    if norm:\n",
    "        Y = np.diag(1/np.linalg.norm(Y,axis=1)).dot(Y)\n",
    "    if row_vecs:\n",
    "        return Y\n",
    "    else:\n",
    "        return Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81649658 -0.53452248 -0.21821789]\n",
      " [ 0.40824829 -0.80178373  0.43643578]\n",
      " [ 0.40824829 -0.26726124 -0.87287156]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[-2, 0, 1 ],[1, -2, 1],[1, -1, 0]])\n",
    "Q = gs(A, row_vecs=False)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gram_schmidt_process(A):\n",
    "    \"\"\"Perform QR decomposition of matrix A using Gram-Schmidt process.\"\"\"\n",
    "    (num_rows, num_cols) = np.shape(A)\n",
    "\n",
    "    # Initialize empty orthogonal matrix Q.\n",
    "    Q = np.empty([num_rows, num_rows])\n",
    "    cnt = 0\n",
    "\n",
    "    # Compute orthogonal matrix Q.\n",
    "    for a in A.T:\n",
    "        u = np.copy(a)\n",
    "        for i in range(0, cnt):\n",
    "            proj = np.dot(np.dot(Q[:, i].T, a), Q[:, i])\n",
    "            u -= proj\n",
    "\n",
    "        e = u / np.linalg.norm(u)\n",
    "        Q[:, cnt] = e\n",
    "\n",
    "        cnt += 1  # Increase columns counter.\n",
    "\n",
    "    # Compute upper triangular matrix R.\n",
    "    R = np.dot(Q.T, A)\n",
    "    return (Q, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.44948974e+00  -1.22474487e+00  -4.08248290e-01]\n",
      " [  2.22044605e-16   1.87082869e+00  -1.33630621e+00]\n",
      " [  7.77156117e-16  -3.77475828e-15   2.18217890e-01]]\n",
      "[[ -2.00000000e+00   1.13508945e-15   1.00000000e+00]\n",
      " [  1.00000000e+00  -2.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00  -1.00000000e+00  -2.08166817e-15]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[-2, 0, 1 ],[1, -2, 1],[1, -1, 0]])\n",
    "Q = gs(A, row_vecs=False)\n",
    "R = Q.T.dot(A)\n",
    "print(R)\n",
    "print(Q.dot(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (1,3) not aligned: 3 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-912df97ec643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_vecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-64149218fc11>\u001b[0m in \u001b[0;36mgs\u001b[0;34m(X, row_vecs, norm)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# * create an extra column(row) matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,) and (1,3) not aligned: 3 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "A = np.array([[-2, 0, 1 ],[1, -2, 1],[1, -1, 0]])\n",
    "Q = gs(A, row_vecs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def householder_reflection(A):\n",
    "    \"\"\"Perform QR decomposition of matrix A using Householder reflection.\"\"\"\n",
    "    (num_rows, num_cols) = np.shape(A)\n",
    "\n",
    "    # Initialize orthogonal matrix Q and upper triangular matrix R.\n",
    "    Q = np.identity(num_rows)\n",
    "    R = np.copy(A)\n",
    "\n",
    "    # Iterative over column sub-vector and\n",
    "    # compute Householder matrix to zero-out lower triangular matrix entries.\n",
    "    for cnt in range(num_rows - 1):\n",
    "        x = R[cnt:, cnt]\n",
    "\n",
    "        e = np.zeros_like(x)\n",
    "        e[0] = copysign(np.linalg.norm(x), -A[cnt, cnt])\n",
    "        u = x + e\n",
    "        v = u / np.linalg.norm(u)\n",
    "\n",
    "        Q_cnt = np.identity(num_rows)\n",
    "        Q_cnt[cnt:, cnt:] -= 2.0 * np.outer(v, v)\n",
    "\n",
    "        R = np.dot(Q_cnt, R)\n",
    "        Q = np.dot(Q, Q_cnt.T)\n",
    "\n",
    "    return (Q, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.        ,  0.4472136 ,  0.89442719],\n",
       "       [ 1.34164079, -1.6       ,  1.8       ],\n",
       "       [ 0.4472136 , -0.2       , -0.4       ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q, r) = householder_reflection(A)\n",
    "\n",
    "r.dot(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
